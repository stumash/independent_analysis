---
title: "USA Crime by City"
author: "Stuart Mashaal"
date: "June 19, 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

Crime rates across the United States vary greatly by state, city, demographic and community type. In metropolitan areas, violent crime and property crime rates area higher than elsewhere.  Rural areas experience from lower rates of both property crime and violent crime.  In cities outside of metropolitan areas, violent crime is lower than the national average while property crime rates are higher than it.  The 50 states have populations and demographics that vary greatly, as does the distribution of those populations and demographics in a given state's cities and rural areas.  This in turn can be responsible for the large variation in crime rates across the states.

This analysis concerns the prevalence of crime accross the United States.  Specifically, this analysis is concerned with determining the relationships, if any, between the rates of different crimes per city and per state in the US in the year 2013.

## The Data

The data used for this analysis was taken from the FBI website, at [www.fbi.gov/table-8/2013](https://www.fbi.gov/about-us/cjis/ucr/crime-in-the-u.s/2013/crime-in-the-u.s.-2013/tables/table-8/table_8_offenses_known_to_law_enforcement_by_state_by_city_2013.xls/view).  The FBI data contains all crime known to law enforcement by city, by state, in the year 2013.  The FBI data is provided in tables with the following variables as columns, one table per state:

Varable Name                         | Type       | Description
-------------------------------------|------------|-----------------------------------------------
City                                 | character  | name of city
Population                           | continuous | number of inhabitants
Violent crime                        | continuous | counts of violent crime
Murder and nonnegligent manslaughter | continuous | counts of murder and nonnegligent manslaughter
Rape (revised definition)1           | continuous | counts of rape under the revised definition
Rape (legacy definition)2            | continuous | counts of rape under the legacy definition
Robbery                              | continuous | counts of robbery
Aggravated assault                   | continuous | counts of aggravated assault
Property crime                       | continuous | counts of property crime
Burglary                             | continuous | counts of burglary
Larceny-theft                        | continuous | counts of larceny
Motor vehicle theft                  | continuous | counts of motor-vehicle theft
Arson3                               | continuous | counts of arson

```{r cache=TRUE, include=FALSE}
##### Exploratory Data Analysis
library(caret)
library(ggplot2)
library(choroplethr)
library(stringr)
library(gridExtra)
load("clean_table.RData")
load("table_per_capita.RData")
load("state_tables.RData")
View(fbi)
View(fbi.pc)
View(states.data)
View(states.data.pc)
nums <- c()
for (i in 1:50) {
  nums <- c(nums, sum(fbi$Violent_crime[fbi.pc$State == levels(fbi.pc$State)[i]]))
}
nums
### eda
## correlations: matrices and vectors
# correlation matrix, displays 0 if correlation is below 0.85
correlations <- matrix(nrow = ncol(fbi) - 2, ncol = ncol(fbi) - 2)
colnames(correlations) <- strtrim(colnames(fbi)[-(1:2)], width = 5)
rownames(correlations) <- colnames(correlations)
for(i in 1:nrow(correlations)) {
  for(j in 1:ncol(correlations)) {
    correlations[i,j] <- cor(fbi[,i+2], fbi[,j+2])
    correlations[i,j] <- ifelse(correlations[i,j]  > 0.85, correlations[i,j], 0)
  }
}
correlations
# population correlated with everything else
sapply(4:13, function(n) {
  cr <- cor(fbi$Population, fbi[,n])
  paste(colnames(fbi)[n], ": ", cr)
})
# correlation matrix for per capita table, displays 0 if correlation is below 0.6
correlations.pc <- matrix(nrow = ncol(fbi.pc) - 2, ncol = ncol(fbi.pc) - 2)
colnames(correlations.pc) <- strtrim(colnames(fbi.pc)[-(1:2)], width = 5)
rownames(correlations.pc) <- colnames(correlations.pc)
for(i in 1:nrow(correlations.pc)) {
  for(j in 1:ncol(correlations.pc)) {
    correlations.pc[i,j] <- cor(fbi.pc[,i+2], fbi.pc[,j+2])
    correlations.pc[i,j] <- ifelse(correlations.pc[i,j]  > 0.6, correlations.pc[i,j], 0)
  }
}
correlations.pc
# population correlated with everything else per capita
sapply(4:13, function(n) {
  cr <- cor(fbi.pc$Population, fbi.pc[,n])
  paste(colnames(fbi.pc)[n], ": ", cr)
})

## choropleths: state total and state per capita
# prepare a data.frame that is formatted correctly for choropleth
states.data.ch <- states.data
rownames(states.data.ch) <- str_replace_all(rownames(states.data.ch), "[_\\-]", " ")
# a data frame for population by state choropleth
popstate <- data.frame(region = rownames(states.data.ch), value = states.data.ch$Population)
# make choropleth
popchor <- StateChoropleth$new(popstate)
popchor$legend = "Population"
popchor$set_num_colors(7)
popchor$set_zoom(NULL)
popchor$show_labels = FALSE
popchor.final = popchor$render()
# a data frame for all crime by state
values <- c()
for(i in 1:50) {
  values <- c(values, sum(states.data.ch[i,-1]))
}
crimstate <- data.frame(region = rownames(states.data.ch), value = values)
crimchor <- StateChoropleth$new(crimstate)
crimchor$legend = "Total Crime"
crimchor$set_num_colors(7)
crimchor$set_zoom(NULL)
crimchor$show_labels = FALSE
crimchor.final = crimchor$render()
# plot both crim and population to show high correlation
grid.arrange(popchor.final, crimchor.final)
# a data frame for violent crime by state
violstate <- data.frame(region = rownames(states.data.ch), value = states.data.ch$Violent_crime)
violchor <- StateChoropleth$new(violstate)
violchor$legend = "Violent Crime"
violchor$set_num_colors(7)
violchor$set_zoom(NULL)
violchor$show_labels = FALSE
violchor.final = violchor$render()
# a data frame for violent crime by state per capita
states.data.pc.ch <- states.data.pc
rownames(states.data.pc.ch) <- str_replace_all(rownames(states.data.pc), "[_\\-]", " ")
violpc <- data.frame(region = rownames(states.data.pc.ch), value = states.data.pc.ch$Violent_crime)
violpcch <- StateChoropleth$new(violpc)
violpcch$legend = "VC Per Capita"
violpcch$set_num_colors(7)
violpcch$set_zoom(NULL)
violpcch$show_labels = FALSE
violpcch.final = violpcch$render()
grid.arrange(violchor.final, violpcch.final)
rm(violpcch, violpc, violchor, popchor, nums, j, i, crimchor, violstate)

##### Modelling
# linear regression model to predict violent crime per city from all other variables, excluding
# variables representing specific kinds of violent crime
cityviollm <- lm(Violent_crime ~ . - Rape - Robbery - Aggravated_assualt - `Murder_and_non-neg_manslaughter` - City - State, fbi)
summary(cityviollm)

# linear regression model to predict violent crime per state from all other variables, 
# excluding variables representing specific types of violent crime
stateviollm <- lm(Violent_crime ~ . - Rape - Robbery - Aggravated_assualt - `Murder_and_non-neg_manslaughter`, states.data)
summary(stateviollm) # good performance using only population

# linear regression model to predict violent crime per city per capita from all other
# variables, exluding variables representing specific types of violent crime
cityviollmpc <- lm(Violent_crime ~ . - Rape - Robbery - Aggravated_assualt - `Murder_and_non-neg_manslaughter` - City - State, fbi.pc)
summary(cityviollmpc)

# linear regression model to predict violent crime per capita from all other variables
stateviollmpc <- lm(Violent_crime ~ . - Rape - Robbery - Aggravated_assualt - `Murder_and_non-neg_manslaughter`, states.data.pc)
summary(stateviollmpc)
```

## Data Preparation

Each of the 50 tables from the FBI websites was on its own page, and so to get all 50 tables required scraping each one off its respective page.  The tables were scraped in a single loop using rvest and stringr for url formatting.  To achieve this, the following code was used:

```{r, eval=FALSE, echo=TRUE}
table.list <- list()
for (i in 1:length(state.names)) {
  curr.state.url <- str_replace(url.template, "STATENAME", state.names[i])
  curr.page <- read_html(curr.state.url)
  curr.nodes <- html_nodes(curr.page, "table")
  curr.table <- html_table(curr.nodes[[3]])
  curr.table$State <- state.names[i]
  table.list[[i]] <- curr.table
}
cn <- c(COL_NAMES)
for (i in 1:50) {
  colnames(table.list[[i]]) <- cn
}
fbi <- do.call(rbind, table.list)
```

The table, fbi, was full of innapropriate data types and NA values. To remove the NA values and format and convert the necessary columns to numerics, the following code was used (requiring the stringr package):

```{r, echo=TRUE, eval=FALSE}
numerify <- function(vec) {
  vec[is.na(vec)] <- 0
  vec <- str_trim(vec)
  vec <- str_replace_all(vec, ",", "")
  vec <- as.numeric(vec)
  vec
}
for (i in 2:13) {
  fbi[,i] <- numerify(fbi[,i])
}
```

The fbi table had two columns for rape: one for counts of rape under a legacy definition and one for rape under a revised definition.  Most cities used exclusively one or the other definition of rape, so the two columns were combined into a single one called 'Rape' using the following code:

```{r, echo=TRUE, eval=FALSE}
fbi$Rape <- fbi$Rape_legacydef + fbi$Rape_reviseddef
fbi <- fbi[,-which(colnames(fbi) %in% c("Rape_legacydef", "Rape_reviseddef"))]
```

Anticipating a trivial and removable relatoinship between city population and the counts of the different offences in that city, the following code produced a second table, fbi.pc, that contained only the per capita counts of each time of crime in each city.

```{r, echo=TRUE, eval=FALSE}
for (i in 4:13) {
  fbi.pc[,i] <- fbi.pc[,i]/fbi.pc[,3]
}
```

Two more tables were produced: 'states.data', summarizing the 'fbi' table to one state per row, and 'states.data.pc' which was the per capita analogue of 'states.data'.  The code below accomplished this:

```{r, eval=FALSE, echo=TRUE}
colnames(states.data) <- colnames(fbi)[-(1:2)]
rownames(states.data) <- levels(fbi$State)
j <- 1
for (currstate in levels(fbi$State)) {
  currstate.data <- fbi[fbi$State == currstate,3:13]
  currstate.row <- c()
  for (i in 1:11) {
    currstate.row <- c(currstate.row, sum(currstate.data[,i]))
  }
  states.data[j,] <- currstate.row
  j <- j + 1
}
states.data.pc <- states.data
for(i in 2:ncol(states.data.pc)) {
  states.data.pc[,i] <- states.data.pc[,i]/states.data.pc[,1]
}
```

These two tables were created in anticipation of exploratory analysis that would reveal stronger relationships between the variables at a state-wide scale or possible geographic relationships that could be exposed when represented on a map of the 50 states.

## Exploratory Analysis

The first step in exploring the data was testing for the 'normality' of the distribution of various crime counts  Histograms revealed that in the fbi table, the distribution of crime rates was definitely not normal.  However, this may have been due to the non normal distribution of populations.  Histograms of the per capita crime rates in the fbi.pc table showed that per capita crime rates were not noramlly distributed either. For example:

```{r, echo=TRUE, eval=TRUE}
range(fbi.pc$Violent_crime)
hist(fbi.pc$Violent_crime, breaks = 300, xlim = c(0, 0.05))
```

The non-normalcy may have been caused by the large number of crime-free, tiny cities in the data.  Regardless, the next step was to determine the level of correlation between the various numeric data.  Correlation matrices were used to this end, on both the original fbi table and its per-capita analague, fbi.pc. 

```{r, eval=FALSE, echo=TRUE}
correlations <- matrix(nrow = ncol(fbi) - 2, ncol = ncol(fbi) - 2)
colnames(correlations) <- strtrim(colnames(fbi)[-(1:2)], width = 5)
rownames(correlations) <- colnames(correlations)
for(i in 1:nrow(correlations)) {
  for(j in 1:ncol(correlations)) {
    correlations[i,j] <- cor(fbi[,i+2], fbi[,j+2])
    correlations[i,j] <- ifelse(correlations[i,j]  > 0.85, correlations[i,j], 0)
  }            # show only correlations greater than 0.85
}
```
```{r, eval=TRUE, echo=FALSE}
correlations
```
```{r, eval=FALSE, echo=TRUE}
correlations.pc <- matrix(nrow = ncol(fbi.pc) - 2, ncol = ncol(fbi.pc) - 2)
colnames(correlations.pc) <- strtrim(colnames(fbi.pc)[-(1:2)], width = 5)
rownames(correlations.pc) <- colnames(correlations.pc)
for(i in 1:nrow(correlations.pc)) {
  for(j in 1:ncol(correlations.pc)) {
    correlations.pc[i,j] <- cor(fbi.pc[,i+2], fbi.pc[,j+2])
    correlations.pc[i,j] <- ifelse(correlations.pc[i,j]  > 0.6, correlations.pc[i,j], 0)
  }                  # show only correlations greater than 0.6
}
```
```{r, eval=TRUE, echo=FALSE}
correlations.pc
```

We see that population is (trivially) strongly correlated the annual counts of numerous types of crime.  Yet, the second matrix shows that population is never correlated stronger than 0.6 with the per-capita rates of any type of crime recorded in the fbi data.  This rejects the claim that population density causes an increase in crime rates.  Both matrices show that the prevalence of many types of crime are correlated strongly with one another, though the second matrix has significantly lower values than the first.

For good measure, lists of the correlation between population and all other variables was computed for both tables.

```{r, echo=TRUE, eval=TRUE}
sapply(4:13, function(n) {
  cr <- cor(fbi$Population, fbi[,n])
  paste(colnames(fbi)[n], ": ", cr)
})
```
```{r, echo=TRUE, eval=TRUE}
sapply(4:13, function(n) {
  cr <- cor(fbi.pc$Population, fbi.pc[,n])
  paste(colnames(fbi.pc)[n], ": ", cr)
})
```

As expected, in the first table, population is very strongly correlated with every single kind of crime besides arson.  In accordance with the trend set by the previous two matrices, the second table of correlations shows that population is not a determinant of per-capita crime rates in a given city.

The last step of the data exploration was determining if the relationships being investigated were more or less pronounced when the data was aggregated by state.  The following plots show, in their similarity or disimilarity, that there is a strong correlation between population and number of violent crimes in a state but a weak correlation between population and violent crimes per capita in a state.

```{r, echo=FALSE, eval=TRUE}
library(gridExtra)
grid.arrange(popchor.final,violchor.final,violpcch.final, layout_matrix = matrix(c(1, 1, 2, 3), nrow = 2, ncol = 2, byrow = TRUE))
```

## Modelling and Modelling Evaluation and Results

A final measure of the relationship between the prevalences of various types of crime and population is the accuracy of predictive models which attempt to determine one value from the others.  Given that all the relevant variables in the data (all four tables) are numeric, simple multivarible linear regression models were the obvious first choice.  One linear model was used to predict violent crime in all four tables, using population and all non-violent crime columns as predictor variables.  The results are shown below.

```{r, eval=TRUE, echo=FALSE}
cityviollm <- lm(Violent_crime ~ . - Rape - Robbery - Aggravated_assualt - `Murder_and_non-neg_manslaughter` - City - State, fbi)
summary(cityviollm)
```
```{r, eval=TRUE, echo=FALSE}
stateviollm <- lm(Violent_crime ~ . - Rape - Robbery - Aggravated_assualt - `Murder_and_non-neg_manslaughter`, states.data)
summary(stateviollm) # good performance using only population
```
```{r, eval=TRUE, echo=FALSE}
cityviollmpc <- lm(Violent_crime ~ . - Rape - Robbery - Aggravated_assualt - `Murder_and_non-neg_manslaughter` - City - State, fbi.pc)
summary(cityviollmpc)
```
```{r, eval=TRUE, echo=FALSE}
stateviollmpc <- lm(Violent_crime ~ . - Rape - Robbery - Aggravated_assualt - `Murder_and_non-neg_manslaughter`, states.data.pc)
summary(stateviollmpc)
```

The results of these models confirm that while there is a relationship between population and crime per capita, the relationship is weak and population alone is not sufficient to predict crime rate per capita.  The models also show that though the per capita rates of many types of crime can be used to predict the per capita rates of other crime on the city-wide level (model 3 R-squared 0.64) to some extent, they are low-accuracy predictors for the data aggregated by state.